{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet and VGG model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm6nZBrU174y",
        "colab_type": "text"
      },
      "source": [
        "**Quoted from Canvas: The assignment is to use keras and from scratch write LeNet and VGG model architectures. Also train on classification task of CAT vs dogs.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxql5Vb_FW4Y",
        "colab_type": "code",
        "outputId": "d930bb77-7c42-47a8-8368-2db8a2974192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51OZLBnXH1-Y",
        "colab_type": "code",
        "outputId": "6a837f42-9a52-4c2e-f7a6-b16c6325b0e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo4yscrSJ_CD",
        "colab_type": "text"
      },
      "source": [
        "**Load Dog/Cat Train & Validation datasets into my Google Drive. This dataset is from Kaggle competition.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG9QqxqLH77e",
        "colab_type": "code",
        "outputId": "90c14dfa-47ec-4ee8-8572-311f3aaec1e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "img_width = 150\n",
        "img_height = 150\n",
        "train_data_dir = '/content/drive/My Drive/Data/train'\n",
        "valid_data_dir = '/content/drive/My Drive/Data/validation'\n",
        "\n",
        "datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(directory=train_data_dir,\n",
        "\t\t\t\t\t\t\t\t\t\t\t   target_size=(img_width,img_height),\n",
        "\t\t\t\t\t\t\t\t\t\t\t   classes=['dogs','cats'],\n",
        "\t\t\t\t\t\t\t\t\t\t\t   class_mode='binary',\n",
        "\t\t\t\t\t\t\t\t\t\t\t   batch_size=16)\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(directory=valid_data_dir,\n",
        "\t\t\t\t\t\t\t\t\t\t\t   target_size=(img_width,img_height),\n",
        "\t\t\t\t\t\t\t\t\t\t\t   classes=['dogs','cats'],\n",
        "\t\t\t\t\t\t\t\t\t\t\t   class_mode='binary',\n",
        "\t\t\t\t\t\t\t\t\t\t\t   batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2048 images belonging to 2 classes.\n",
            "Found 832 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAbKS9XqI1PD",
        "colab_type": "text"
      },
      "source": [
        "**First, build a standard CNN Model to train dag/cat classification. This is for reference only, not required for this assignment.**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c4gQsgxDv8W",
        "colab_type": "code",
        "outputId": "e1e61b22-3c90-48fd-90c1-58d6c9f28895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "source": [
        "\n",
        "\n",
        "model =Sequential()\n",
        "\n",
        "model.add(Conv2D(32,(3,3), input_shape=(img_width, img_height, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(32,(3,3), input_shape=(img_width, img_height, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(64,(3,3), input_shape=(img_width, img_height, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "\n",
        "print('cnn model complied!!')\n",
        "\n",
        "print('starting training....')\n",
        "training = model.fit_generator(generator=train_generator, steps_per_epoch=2048 // 16,epochs=2,validation_data=validation_generator,validation_steps=832//16)\n",
        "\n",
        "print('training finished!!')\n",
        "\n",
        "print('saving weights to simple_CNN.h5')\n",
        "\n",
        "model.save_weights('/content/drive/My Drive/Data/simple_CNN.h5')\n",
        "\n",
        "print('all cnn weights saved successfully !!')\n",
        "#models.load_weights('models/simple_CNN.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "model complied!!\n",
            "starting training....\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/2\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "128/128 [==============================] - 90s 706ms/step - loss: 0.7515 - acc: 0.5210 - val_loss: 0.6828 - val_acc: 0.5577\n",
            "Epoch 2/2\n",
            "128/128 [==============================] - 87s 678ms/step - loss: 0.6679 - acc: 0.5986 - val_loss: 0.6274 - val_acc: 0.6779\n",
            "training finished!!\n",
            "saving weights to simple_CNN.h5\n",
            "all weights saved successfully !!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FZI3dgjh_GR",
        "colab_type": "text"
      },
      "source": [
        "**VGG 16 Architecutre and Application for cat/dog training. I adjusted Epoch parameter to 2 due to the prolonged time consumption otherwise (Usually need 20 epochs by convention). The second epoch accuracy is showing improved result from the first epoch.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWRo9lttgbeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Flatten, Dense, Dropout\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.optimizers import SGD\n",
        "import cv2, numpy as np "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKR57559MuRM",
        "colab_type": "code",
        "outputId": "918d09b5-2016-42a4-a362-d998a3b3cb23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(ZeroPadding2D((1,1),input_shape=(img_width, img_height, 3)))\n",
        "model.add(Convolution2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), strides=1, activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2), data_format='channels_last'))\n",
        "\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2), data_format='channels_last'))\n",
        "\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2), data_format='channels_last'))\n",
        "\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2), data_format='channels_last'))\n",
        "\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2), data_format='channels_last'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "\n",
        "print('VGG 16 model complied!!')\n",
        "\n",
        "print('starting training....')\n",
        "training = model.fit_generator(generator=train_generator, steps_per_epoch=2048 // 16,epochs=2,validation_data=validation_generator,validation_steps=832//16)\n",
        "\n",
        "print('training finished!!')\n",
        "\n",
        "print('saving weights to VGG_CNN.h5')\n",
        "\n",
        "model.save_weights('/content/drive/My Drive/Data/VGG_CNN.h5')\n",
        "\n",
        "print('all VGG16 weights saved successfully !!')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model complied!!\n",
            "starting training....\n",
            "Epoch 1/2\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "128/128 [==============================] - 2258s 18s/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 2/2\n",
            "  1/128 [..............................] - ETA: 27:53 - loss: 2.9892 - acc: 0.8125"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNcOwLScMhxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.contrib.layers import flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5PCwT42LwX0",
        "colab_type": "text"
      },
      "source": [
        "**LeNet Architech and Application to train dog/cat classification. Similar as above, I adjusted Epoch parameter to \"2\" due to the prolonged time consultion due to CPU/GPU limitation. The second epoch indeed shows improved classification accuracy from the first epoch.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX9MAxPYMnF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 6, \n",
        "                 kernel_size = 5, \n",
        "                 strides = 1, \n",
        "                 activation = 'relu', \n",
        "                 input_shape = (32,32,1)))\n",
        "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
        "model.add(Conv2D(filters = 16, \n",
        "                 kernel_size = 5,\n",
        "                 strides = 1,\n",
        "                 activation = 'relu',\n",
        "                 input_shape = (14,14,6)))\n",
        "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units = 120, activation = 'relu'))\n",
        "model.add(Dense(units = 84, activation = 'relu'))\n",
        "model.add(Dense(units = 10, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "\n",
        "print('LeNet model complied!!')\n",
        "\n",
        "print('starting training....')\n",
        "training = model.fit_generator(generator=train_generator, steps_per_epoch=2048 // 16,epochs=2,validation_data=validation_generator,validation_steps=832//16)\n",
        "\n",
        "print('training finished!!')\n",
        "\n",
        "print('saving weights to LeNet_CNN.h5')\n",
        "\n",
        "model.save_weights('/content/drive/My Drive/Data/LeNet_CNN.h5')\n",
        "\n",
        "print('all LeNet weights saved successfully !!')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}